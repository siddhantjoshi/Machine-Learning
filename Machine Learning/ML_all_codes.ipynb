{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# y=mx-c model to predict from the data given\n",
    "# m= 2 and c= 1\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "xs=np.array([-1.0, 0.0, 1.0, 2.0], dtype=float)\n",
    "ys=np.array([-3.0, -1.0, 1.0, 3.0], dtype=float)\n",
    "\n",
    "model.fit(xs, ys, epochs=1000)\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# mnist fashion dataset use to find the shoe from the data feed \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#make a class callBack to stop the trainning if we got the acurracy upto 95 %\n",
    "class callback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epochs, logs={}):\n",
    "        if(logs.get('acc')>0.9):\n",
    "            print(\"\\n Reached 90% accuracy so stop training the model \")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks=callback()\n",
    "\n",
    "fashion_minst =tf.keras.datasets.fashion_mnist\n",
    "(training_images, tarining_labels),(test_images, test_labels) = fashion_minst.load_data()\n",
    "\n",
    "\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Flatten(),\n",
    "                       tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                       tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "                       ])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images,tarining_labels,epochs=15,callbacks=[callbacks])\n",
    "model.evaluate(test_images, test_labels) \n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "\n",
    "print(test_labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# mnist fashion dataset  solve using convolution layer\n",
    "\n",
    "#import cv2\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "i=misc.ascent()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.grid(False)\n",
    "plt.gray()\n",
    "plt.axis('off')\n",
    "plt.imshow(i)\n",
    "plt.show()\n",
    "\n",
    "i_transformed = np.copy(i)\n",
    "# get the dimension's of image \n",
    "size_x = i_transformed.shape[0]\n",
    "size_y = i_transformed.shape[1]\n",
    "\n",
    "#set the filter by which we going to filter the image as per our desired\n",
    "filter=[[-1, -2, -1],[0, 0, 0],[1, 2, 1]]\n",
    "weight = 1\n",
    "\n",
    "for x in range(1, size_x-1):\n",
    "    for y in range(1, size_y-1):\n",
    "        output_pixel = 0.0\n",
    "        \n",
    "        output_pixel = output_pixel + (i[x-1,y-1] * filter[0][0])\n",
    "        output_pixel = output_pixel + (i[x+0,y-1] * filter[0][1])\n",
    "        output_pixel = output_pixel + (i[x+1,y-1] * filter[0][2])\n",
    "        \n",
    "        output_pixel = output_pixel + (i[x-1,y+0] * filter[1][0])\n",
    "        output_pixel = output_pixel + (i[x+0,y+0] * filter[1][1])\n",
    "        output_pixel = output_pixel + (i[x+1,y+0] * filter[1][2])\n",
    "        \n",
    "        output_pixel = output_pixel + (i[x-1,y+1] * filter[2][0])\n",
    "        output_pixel = output_pixel + (i[x+0,y+1] * filter[2][1])\n",
    "        output_pixel = output_pixel + (i[x+1,y+1] * filter[2][2])\n",
    "        \n",
    "        output_pixel = output_pixel *weight\n",
    "        \n",
    "        if(output_pixel < 0):\n",
    "            output_pixel = 0\n",
    "        if(output_pixel > 255):\n",
    "            output_pixel = 255\n",
    "\n",
    "        i_transformed[x, y] = output_pixel\n",
    "        \n",
    "# plot the image\n",
    "plt.gray()\n",
    "plt.grid(False)\n",
    "plt.imshow(i_transformed)\n",
    "plt.show()\n",
    "\n",
    "# pooling the image (compressing image )\n",
    "\n",
    "new_x = int(size_x/2)\n",
    "new_y = int(size_y/2)\n",
    "newImage = np.zeros((new_x, new_y))\n",
    "\n",
    "# iterate the from 0 to size_x with differnce of 2  \n",
    "for x in range(0, size_x, 2):\n",
    "    for y in range(0, size_y, 2):\n",
    "        pixels = []\n",
    "        \n",
    "        pixels.append(i_transformed[x+0, y+0])\n",
    "        pixels.append(i_transformed[x+1, y+0])\n",
    "        \n",
    "        pixels.append(i_transformed[x+0, y+1])\n",
    "        pixels.append(i_transformed[x+1, y+1])\n",
    "        \n",
    "        pixels.sort(reverse =True)\n",
    "        newImage[int(x/2), int(y/2)] = pixels[0]\n",
    "    \n",
    "# plot the compressed image\n",
    "\n",
    "plt.gray()\n",
    "plt.grid(False)\n",
    "plt.imshow(newImage)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#sve the dataset into one variable \n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "#load the data as per the lables\n",
    "(training_images, tarining_labels),(test_images, test_labels)=mnist.load_data()\n",
    "\n",
    "#reshape the images\n",
    "training_images = training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images/255.0\n",
    "\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0\n",
    "\n",
    "#prepare model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape = (28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    #add convolution layer to it\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    \n",
    "    #flatten the output\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    #128 layer's\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile the code and train the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(training_images, training_lables, epochs=5)\n",
    "\n",
    "#show the over-all  accuaracy and print the result \n",
    "test_loss,test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(\"Test loss: {},Test accuracy: {}\".format(test_loss, test_accuracy*100))\n",
    "\n",
    "#print teh first 100 lable's\n",
    "print(test_labels[:100])\n",
    "\n",
    "#plot the image using the matplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, axarr = plt.subplots(3, 4)\n",
    "\n",
    "FIRST_IMAGE = 0\n",
    "SECOND_IMAGE = 23\n",
    "THIRD_IMAGE = 28\n",
    "CONVOLUTION_NUMBER = 6 \n",
    "\n",
    "from tensorflow.keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "\n",
    "for x in range(0, 4):\n",
    "    \n",
    "    f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[0, x].imshow(f1[0, : ,:, CONVOLUTION_NUMBER],cmap='inferno')\n",
    "    axarr[0, x].grid(False)\n",
    "    \n",
    "    f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[1, x].imshow(f2[0, : ,:, CONVOLUTION_NUMBER],cmap='inferno')\n",
    "    axarr[1, x].grid(False)\n",
    "    \n",
    "    f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[2, x].imshow(f3[0, : ,:, CONVOLUTION_NUMBER],cmap='inferno')\n",
    "    axarr[2, x].grid(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "#to create the decission tree\n",
    "#data feeded is [height, weigth, shoe-size]\n",
    "values=[[181, 80, 44],[177, 70, 43],[160, 60, 38],[151, 530, 44],[191, 90, 54],[154, 65, 77],[158, 80, 44],\n",
    "        [185, 80, 44],[154, 80, 44],[156, 80, 45],[199, 80, 44],[178, 56, 44],[181, 90, 44],[125, 98, 35]]\n",
    "\n",
    "community=['male', 'female','female', 'male', 'male','female','female',\n",
    "           'female', 'female' ,'male', 'male', 'female','male', 'male']\n",
    "\n",
    "create_tree = tree.DecisionTreeClassifier()\n",
    "create_tree=create_tree.fit(values, community)\n",
    "\n",
    "prediction = create_tree.predict([[208,65,60]])\n",
    "\n",
    "print(prediction) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lightfm.datasets import fetch_movielens\n",
    "from lightfm import LightFM\n",
    "\n",
    "# fetch the data\n",
    "data = fetch_movielens(min_rating = 4.0)\n",
    "\n",
    "print(repr(data['train']))\n",
    "print(repr(data['test']))\n",
    "\n",
    "#Create Model\n",
    "\n",
    "model = LightFM(loss = 'warp')\n",
    "model.fit(data['train'], epochs = 30, num_threads = 20 )\n",
    "\n",
    "def SampleRecomendation(model, data, user_ids):\n",
    "    number_users, number_items = data['train'].shape\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
    "        score = model.predict(user_id, np.arange(number_users))\n",
    "        top_items = data['item_labels'][np.argsort(-score)]\n",
    "        \n",
    "        print(\"user %s\"%user_id)\n",
    "        print(\"      Know positive : \")\n",
    "        \n",
    "        for x in known_positives[:3]:\n",
    "            print(\"              %s\" % x)\n",
    "            \n",
    "        print(\"         Recomended :\")\n",
    "        \n",
    "        for x in top_items[:3]:\n",
    "            print(\"         %s\" % x)\n",
    "\n",
    "SampleRecomendation(model, data, [3, 25, 450])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightFM\n",
      "  Using cached https://files.pythonhosted.org/packages/e9/8e/5485ac5a8616abe1c673d1e033e2f232b4319ab95424b42499fabff2257f/lightfm-1.15.tar.gz\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from lightFM) (1.16.4)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from lightFM) (1.2.1)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\lib\\site-packages (from lightFM) (2.22.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->lightFM) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->lightFM) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->lightFM) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests->lightFM) (3.0.4)\n",
      "Building wheels for collected packages: lightFM\n",
      "  Building wheel for lightFM (setup.py): started\n",
      "  Building wheel for lightFM (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for lightFM\n",
      "Failed to build lightFM\n",
      "Installing collected packages: lightFM\n",
      "  Running setup.py install for lightFM: started\n",
      "    Running setup.py install for lightFM: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Complete output from command 'C:\\Users\\admin\\Anaconda3\\python.exe' -u -c 'import setuptools, tokenize;__file__='\"'\"'C:\\\\Users\\\\admin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-yudhd98q\\\\lightFM\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\admin\\AppData\\Local\\Temp\\pip-wheel-snfu6gj4' --python-tag cp37:\n",
      "  ERROR: Compiling without OpenMP support.\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.7\n",
      "  creating build\\lib.win-amd64-3.7\\lightfm\n",
      "  copying lightfm\\cross_validation.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "  copying lightfm\\data.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "  copying lightfm\\evaluation.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "  copying lightfm\\lightfm.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "  copying lightfm\\_lightfm_fast.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "  copying lightfm\\__init__.py -> build\\lib.win-amd64-3.7\\lightfm\n",
      "  creating build\\lib.win-amd64-3.7\\lightfm\\datasets\n",
      "  copying lightfm\\datasets\\movielens.py -> build\\lib.win-amd64-3.7\\lightfm\\datasets\n",
      "  copying lightfm\\datasets\\stackexchange.py -> build\\lib.win-amd64-3.7\\lightfm\\datasets\n",
      "  copying lightfm\\datasets\\_common.py -> build\\lib.win-amd64-3.7\\lightfm\\datasets\n",
      "  copying lightfm\\datasets\\__init__.py -> build\\lib.win-amd64-3.7\\lightfm\\datasets\n",
      "  copying lightfm\\_lightfm_fast_no_openmp.c -> build\\lib.win-amd64-3.7\\lightfm\n",
      "  copying lightfm\\_lightfm_fast_openmp.c -> build\\lib.win-amd64-3.7\\lightfm\n",
      "  running build_ext\n",
      "  building 'lightfm._lightfm_fast_no_openmp' extension\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": https://visualstudio.microsoft.com/downloads/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for lightFM\n",
      "  ERROR: Complete output from command 'C:\\Users\\admin\\Anaconda3\\python.exe' -u -c 'import setuptools, tokenize;__file__='\"'\"'C:\\\\Users\\\\admin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-yudhd98q\\\\lightFM\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' clean --all:\n",
      "  ERROR: Compiling without OpenMP support.\n",
      "  running clean\n",
      "  error: [WinError 2] The system cannot find the file specified\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed cleaning build dir for lightFM\n",
      "    ERROR: Complete output from command 'C:\\Users\\admin\\Anaconda3\\python.exe' -u -c 'import setuptools, tokenize;__file__='\"'\"'C:\\\\Users\\\\admin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-yudhd98q\\\\lightFM\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\admin\\AppData\\Local\\Temp\\pip-record-erkrwxs1\\install-record.txt' --single-version-externally-managed --compile:\n",
      "    ERROR: Compiling without OpenMP support.\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    running build_ext\n",
      "    building 'lightfm._lightfm_fast_no_openmp' extension\n",
      "    error: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": https://visualstudio.microsoft.com/downloads/\n",
      "    ----------------------------------------\n",
      "ERROR: Command \"'C:\\Users\\admin\\Anaconda3\\python.exe' -u -c 'import setuptools, tokenize;__file__='\"'\"'C:\\\\Users\\\\admin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-yudhd98q\\\\lightFM\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\admin\\AppData\\Local\\Temp\\pip-record-erkrwxs1\\install-record.txt' --single-version-externally-managed --compile\" failed with error code 1 in C:\\Users\\admin\\AppData\\Local\\Temp\\pip-install-yudhd98q\\lightFM\\\n"
     ]
    }
   ],
   "source": [
    "pip install lightFM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-eff0e42b519b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-eff0e42b519b>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pip install lightFM\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install lightFM\n",
    "import numpy as np\n",
    "from lightfm.datasets import fetch_movielens\n",
    "from lightfm import LightFM\n",
    "\n",
    "# fetch the data\n",
    "data = fetch_movielens(min_rating = 4.0)\n",
    "\n",
    "print(repr(data['train']))\n",
    "print(repr(data['test']))\n",
    "\n",
    "#Create Model\n",
    "\n",
    "model = LightFM(loss = 'warp')\n",
    "model.fit(data['train'], epochs = 30, num_threads = 20 )\n",
    "\n",
    "def SampleRecomendation(model, data, user_ids):\n",
    "    number_users, number_items = data['train'].shape\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
    "        score = model.predict(user_id, np.arange(number_users))\n",
    "        top_items = data['item_labels'][np.argsort(-score)]\n",
    "        \n",
    "        print(\"user %s\"%user_id)\n",
    "        print(\"      Know positive : \")\n",
    "        \n",
    "        for x in known_positives[:3]:\n",
    "            print(\"              %s\" % x)\n",
    "            \n",
    "        print(\"         Recomended :\")\n",
    "        \n",
    "        for x in top_items[:3]:\n",
    "            print(\"         %s\" % x)\n",
    "\n",
    "SampleRecomendation(model, data, [3, 25, 450])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "from functools import partial\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import urllib.request\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOT\n",
    "from sklearn.cross_validation  import trai\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
